{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原理\n",
    "\n",
    "帧差法：\n",
    "\n",
    "将连续两帧的图像数据进行差分法，即进行相减操作, 如果其相减后的绝对值大于阈值，则像素点变为255， 否则变为0，通过这种方法来找出视频中运动的物体\n",
    "\n",
    "\n",
    "混合高斯模型：\n",
    "\n",
    "将图像分为3-5个高斯模型，一个像素点来了，如果该像素点离任何一个高斯模型的距离大于其2倍的标准差，则为前景即运动物体，否则则是背景\n",
    "\n",
    "           帧差法步骤：第一步：初始各种参数\n",
    "\n",
    "           第二步：使用T帧图像构造模型，对于第一个帧图像的第一个像素点，使用u1，σ1构造高斯模型\n",
    "\n",
    "           第三步：对于一个新来的模型，如果该像素在高斯模型3*σ1内，则属于该高斯模型，对参数进行更新\n",
    "\n",
    "           第四步：如果不满足该高斯模型，重新建立一个新的高斯模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 步骤说明：\n",
    "\n",
    "第一步：使用cv2.VideoCapture() 构造读取模型\n",
    "\n",
    "第二步：使用cv2.getStructureElement(cv2.MORPH_ELLIPSE, （3, 3)) # 构造形态学使用的kernel，即np.ones((3, 3), np.uint8)\n",
    "\n",
    "第三步：构造cv2.createBackgroundSubtractorMOG2() 实例化混合高斯模型\n",
    "\n",
    "第四步：cap.read()从视频中读取文件，并使用model.apply(frame) 使用上混合高斯模型\n",
    "\n",
    "第五步：使用cv2.morpholyEx(image, cv2.MORPH_OPEN, kernel) 使用开运算进行噪音的去除\n",
    "\n",
    "第六步：cv2.findCountours找出图片中的轮廓，对其进行循环\n",
    "\n",
    "第七步：对于周长大于188的轮廓，使用cv2.boundingRect计算外接矩阵，使用cv2.rectangle画出外接矩阵，作为人\n",
    "\n",
    "第八步：使用cv2.imshow()展示图片，使用cv2.waitkey(150) & 0xff == 27来延长放映的时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOG2算法\n",
    "也是高斯混合模型分离算法，是MOG的改进算法。它基于Z.Zivkovic发布的两篇论文，即2004年发布的“Improved adaptive Gausian mixture model for background subtraction”和2006年发布的“Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction”中提出。\n",
    "\n",
    "该算法的一个重要特征是 它为每个像素选择适当数量的高斯分布，它可以更好地适应不同场景的照明变化等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:19:19.064440Z",
     "start_time": "2021-02-23T11:19:18.771507Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imageio\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:19:20.990219Z",
     "start_time": "2021-02-23T11:19:20.984487Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def bgMOG2(cap):\n",
    "    # 构造形态学使用的kernel，即np.ones((3, 3), np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) \n",
    "    # fgbg1 = cv2.createBackgroundSubtractorMOG()\n",
    "    fgbg2 = cv2.createBackgroundSubtractorMOG2()\n",
    "    frame_list=[]\n",
    "    mask_list=[]\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('not found')\n",
    "            break\n",
    "        frame = cv2.resize(frame, (1280,960), interpolation = cv2.INTER_CUBIC)\n",
    "    #     fgmask1 = fgbg1.apply(frame)\n",
    "\n",
    "        # 运用高斯模型进行拟合，在两个标准差内设置为0，在两个标准差外设置为255\n",
    "        fgmask2 = fgbg2.apply(frame)\n",
    "    #     fgmask3 = fgbg3.apply(frame)\n",
    "\n",
    "        fgmask4 = cv2.morphologyEx(fgmask2, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "        contours = cv2.findContours(fgmask4, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "        for c in contours:\n",
    "            # 第七步：进行人的轮廓判断，使用周长，符合条件的画出外接矩阵的方格\n",
    "            length = cv2.arcLength(c, True)\n",
    "\n",
    "            if length > 200:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "        frame_list.append(fgmask4)\n",
    "        mask_list.append(frame[:,:,(2,1,0)])\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.imshow(\"bgMOG2\", fgmask4)\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "            break\n",
    "    return frame_list, mask_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用KNN根据前景面积检测运动物体\n",
    "\n",
    "也是高斯混合模型分离算法，是MOG的改进算法。它基于Z.Zivkovic发布的两篇论文，即2004年发布的“Improved adaptive Gausian mixture model for background subtraction”和2006年发布的“Efficient Adaptive Density Estimation per Image Pixel for the Task of Background Subtraction”中提出。\n",
    "\n",
    "该算法的一个重要特征是 它为每个像素选择适当数量的高斯分布，它可以更好地适应不同场景的照明变化等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T11:21:28.459Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 使用KNN根据前景面积检测运动物体\n",
    "def bgSubtractorKNN(cap):\n",
    "    history = 20    # 训练帧数\n",
    " \n",
    "    bs = cv2.createBackgroundSubtractorKNN(detectShadows=True)  # 背景减除器，设置阴影检测\n",
    "    bs.setHistory(history)\n",
    " \n",
    "    frames = 0\n",
    "    frame_list=[]\n",
    "    mask_list=[]\n",
    " \n",
    "    while True:\n",
    "        res, tmp_frame = cap.read()      \n",
    "        \n",
    "        if not res:\n",
    "            break\n",
    "        frame = cv2.resize(tmp_frame,(1280,720))\n",
    "        \n",
    "        fg_mask = bs.apply(frame)   # 获取 foreground mask\n",
    " \n",
    "        if frames < history:\n",
    "            frames += 1\n",
    "            continue\n",
    " \n",
    "        # 对原始帧进行膨胀去噪\n",
    "        th = cv2.threshold(fg_mask.copy(), 244, 255, cv2.THRESH_BINARY)[1]\n",
    "        th = cv2.erode(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2)), iterations=2)\n",
    "        dilated = cv2.dilate(th, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2)), iterations=2)\n",
    "        # 获取所有检测框\n",
    "        img, contours, hier = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    " \n",
    "\n",
    "#         # draw a bounding box arounded the detected barcode and display the image\n",
    "#         cv.drawContours(image, [box], -1, (0, 255, 0), 3)\n",
    "\n",
    "#         c = sorted(contours, key=cv.contourArea, reverse=True)[0]\n",
    "#         rect = cv.minAreaRect(c)\n",
    "#         box = np.int0(cv.boxPoints(rect))\n",
    "            \n",
    "        for c in contours:\n",
    "            # 获取矩形框边界坐标\n",
    "            x, y, w, h = cv2.boundingRect(c)\n",
    "            # 计算矩形框的面积\n",
    "            area = cv2.contourArea(c)\n",
    "            if 800 < area:\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "        frame_list.append(dilated)\n",
    "        mask_list.append(frame[:,:,(2,1,0)])\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "#         cv2.imshow(\"bgKNN\", dilated)\n",
    "        if cv2.waitKey(100) & 0xff == 27:\n",
    "            break\n",
    "    return frame_list, mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOG算法，\n",
    "\n",
    "即高斯混合模型分离算法，全称Gaussian Mixture-based Background/Foreground Segmentation Algorithm。2001年，由P.KadewTraKuPong和R.Bowden在论文“An improved adaptive background mixture model for real-time tracking with shadow detection”中提出。\n",
    "\n",
    "它使用一种通过K高斯分布的混合来对每个背景像素进行建模的方法(K = 3〜5）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:19:31.389022Z",
     "start_time": "2021-02-23T11:19:31.375426Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def bgMOG(cap):\n",
    "        # 构造形态学使用的kernel，即np.ones((3, 3), np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)) \n",
    "    history = 20\n",
    "    frame_list=[]\n",
    "    mask_list=[]\n",
    "    fgbg2 = cv2.bgsegm.createBackgroundSubtractorMOG(history)\n",
    "    fgbg2.setHistory(history)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('not found')\n",
    "            break\n",
    "        frame = cv2.resize(frame, (400,400), interpolation = cv2.INTER_CUBIC)\n",
    "    #     fgmask1 = fgbg1.apply(frame)\n",
    "\n",
    "        # 运用高斯模型进行拟合，在两个标准差内设置为0，在两个标准差外设置为255\n",
    "        fgmask2 = fgbg2.apply(frame)\n",
    "    #     fgmask3 = fgbg3.apply(frame)          \n",
    "                \n",
    "                \n",
    "\n",
    "        fgmask4 = cv2.morphologyEx(fgmask2, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "        img, contours,hier = cv2.findContours(fgmask4, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for c in contours:\n",
    "            # 第七步：进行人的轮廓判断，使用周长，符合条件的画出外接矩阵的方格\n",
    "            length = cv2.arcLength(c, True)\n",
    "\n",
    "            if 50000 > length > 150:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        frame_list.append(fgmask4)\n",
    "        mask_list.append(frame[:,:,(2,1,0)])\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        cv2.imshow(\"bgMOG\", fgmask4)\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "            break\n",
    "    return frame_list, mask_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMG\n",
    "\n",
    "该算法结合统计背景图像估计和每像素贝叶斯分割。由 Andrew B. Godbehere, Akihiro Matsukawa, Ken Goldberg在2012年的文章“Visual Tracking of Human Visitors under Variable-Lighting Conditions for a Responsive Audio Art Installation”中提出。\n",
    "该算法使用前几个（默认为120）帧进行后台建模。它采用概率前景分割算法，使用贝叶斯推理识别可能的前景对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-23T11:19:45.142926Z",
     "start_time": "2021-02-23T11:19:45.119613Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def bgGMG(cap):\n",
    "        # 构造形态学使用的kernel，即np.ones((3, 3), np.uint8)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (10, 10)) \n",
    "    history = 20\n",
    "    frame_list=[]\n",
    "    mask_list=[]\n",
    "    \n",
    "    # fgbg1 = cv2.createBackgroundSubtractorMOG()\n",
    "    fgbg2 = cv2.bgsegm.createBackgroundSubtractorGMG(initializationFrames= history)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('not found')\n",
    "            break\n",
    "        frame = cv2.resize(frame, (400,400), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        # 运用高斯模型进行拟合，在两个标准差内设置为0，在两个标准差外设置为255\n",
    "        fgmask2 = fgbg2.apply(frame)\n",
    "\n",
    "        fgmask2 = cv2.morphologyEx(fgmask2, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "        contours = cv2.findContours(fgmask2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "        for c in contours:\n",
    "            # 第七步：进行人的轮廓判断，使用周长，符合条件的画出外接矩阵的方格\n",
    "            length = cv2.arcLength(c, True)\n",
    "\n",
    "            if 500 > length > 100:\n",
    "                (x, y, w, h) = cv2.boundingRect(c)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "        frame_list.append(fgmask2)\n",
    "        mask_list.append(frame[:,:,(2,1,0)])\n",
    "        cv2.imshow(\"img\", frame)\n",
    "        cv2.imshow(\"bgGMG\", fgmask2)\n",
    "        if cv2.waitKey(110) & 0xff == 27:\n",
    "            break\n",
    "    return frame_list, mask_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-23T11:21:39.783Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cap = cv2.VideoCapture(\"/data/disk2/01_dataset/02_shuohuang/04_classification/01hand.mp4\")\n",
    "    bgKNN = \"bgKNN.gif\"\n",
    "    bg_MOG = \"bgMOG.gif\"\n",
    "    bg_MOG2 = \"bgMOG2.gif\"\n",
    "    bg_GMG = \"bgGMG.gif\"\n",
    "    \n",
    "    oriKNN = \"oriKNN.gif\"\n",
    "    oriMOG = \"oriMOG.gif\"\n",
    "    \n",
    "    oriMOG2 = \"oriMOG2.gif\"\n",
    "    oriGMG = \"oriGMG.gif\"\n",
    "\n",
    "    frame_list, mask_list = bgSubtractorKNN(cap)\n",
    "#     frame_list, mask_list = bgMOG2(cap)\n",
    "#     frame_list, mask_list = bgMOG(cap)\n",
    "#     frame_list, mask_list = bgGMG(cap)\n",
    "    \n",
    "#     imageio.mimsave(bg_GMG, mask_list, 'GIF', duration=0.05)\n",
    "#     imageio.mimsave(oriGMG, frame_list, 'GIF', duration=0.05)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "附件",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
